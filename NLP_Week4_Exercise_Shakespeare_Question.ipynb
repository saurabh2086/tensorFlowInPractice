{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Week4_Exercise_Shakespeare_Question.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabh2086/tensorFlowInPractice/blob/master/NLP_Week4_Exercise_Shakespeare_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOwsuGQQY9OL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "### YOUR CODE HERE\n",
        "# Figure out how to import regularizers\n",
        "###\n",
        "import tensorflow.keras.utils as ku \n",
        "import numpy as np "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32QrAqlqUbnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WXQPsl0UeyA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "b7c18e8f-d220-456d-ae59-e86ce83c248b"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n",
        "    -O /tmp/sonnets.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-10 05:19:00--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.212.128, 2607:f8b0:4001:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.212.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93578 (91K) [text/plain]\n",
            "Saving to: ‘/tmp/sonnets.txt’\n",
            "\n",
            "\r/tmp/sonnets.txt      0%[                    ]       0  --.-KB/s               \r/tmp/sonnets.txt    100%[===================>]  91.38K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2019-07-10 05:19:01 (94.7 MB/s) - ‘/tmp/sonnets.txt’ saved [93578/93578]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCb0er1_UiqK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "c974d5f9-5159-4b43-bcf8-dc3cc6a088cc"
      },
      "source": [
        "data = open('/tmp/sonnets.txt').read()\n",
        "print(data[:500])\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FROM fairest creatures we desire increase,\n",
            "That thereby beauty's rose might never die,\n",
            "But as the riper should by time decease,\n",
            "His tender heir might bear his memory:\n",
            "But thou, contracted to thine own bright eyes,\n",
            "Feed'st thy light'st flame with self-substantial fuel,\n",
            "Making a famine where abundance lies,\n",
            "Thyself thy foe, to thy sweet self too cruel.\n",
            "Thou that art now the world's fresh ornament\n",
            "And only herald to the gaudy spring,\n",
            "Within thine own bud buriest thy content\n",
            "And, tender churl, makes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrwfqnOSU5tC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5c44e74e-b1c5-498c-ff9f-74d5ab165304"
      },
      "source": [
        "corpus = data.lower().split(\"\\n\")\n",
        "print(corpus[0:10])\n",
        "print(len(corpus))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['from fairest creatures we desire increase,', \"that thereby beauty's rose might never die,\", 'but as the riper should by time decease,', 'his tender heir might bear his memory:', 'but thou, contracted to thine own bright eyes,', \"feed'st thy light'st flame with self-substantial fuel,\", 'making a famine where abundance lies,', 'thyself thy foe, to thy sweet self too cruel.', \"thou that art now the world's fresh ornament\", 'and only herald to the gaudy spring,']\n",
            "2159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXIUAbeLVHFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.fit_on_texts(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQzS2cZ-VSkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_words = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfslCUyFWGr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1, len(token_list)):\n",
        "    n_gram_sequence = token_list[:i+1]\n",
        "    input_sequences.append(n_gram_sequence)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHuvE4b6WLY_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "129066a1-1e85-41c5-ccad-ac21c320bfc7"
      },
      "source": [
        "input_sequences[0:10]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[34, 417],\n",
              " [34, 417, 877],\n",
              " [34, 417, 877, 166],\n",
              " [34, 417, 877, 166, 213],\n",
              " [34, 417, 877, 166, 213, 517],\n",
              " [8, 878],\n",
              " [8, 878, 134],\n",
              " [8, 878, 134, 351],\n",
              " [8, 878, 134, 351, 102],\n",
              " [8, 878, 134, 351, 102, 156]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PRnDnCW-Z7qv",
        "colab": {}
      },
      "source": [
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "label = ku.to_categorical(label, num_classes=total_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6bH6yldZDAM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4fc2f59d-aa8a-46e5-8929-04c8eac32368"
      },
      "source": [
        "max_sequence_len"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9vH8Y59ajYL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "f09899dd-7936-485e-9a39-a82b0cd568da"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 10, 100)           321100    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 10, 300)           301200    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 10, 300)           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100)               160400    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1605)              162105    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3211)              5156866   \n",
            "=================================================================\n",
            "Total params: 6,101,671\n",
            "Trainable params: 6,101,671\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIg2f1HBxqof",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e38df39-cef2-4702-a8c0-d41bba8cc64b"
      },
      "source": [
        " history = model.fit(predictors, label, epochs=100, verbose=1)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0710 05:40:45.301758 140565834557312 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "15462/15462 [==============================] - 26s 2ms/sample - loss: 6.9008 - acc: 0.0235\n",
            "Epoch 2/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 6.5022 - acc: 0.0213\n",
            "Epoch 3/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 6.3741 - acc: 0.0255\n",
            "Epoch 4/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 6.2527 - acc: 0.0321\n",
            "Epoch 5/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 6.1624 - acc: 0.0362\n",
            "Epoch 6/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 6.0858 - acc: 0.0397\n",
            "Epoch 7/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 6.0032 - acc: 0.0412\n",
            "Epoch 8/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 5.9163 - acc: 0.0456\n",
            "Epoch 9/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 5.8107 - acc: 0.0524\n",
            "Epoch 10/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 5.7028 - acc: 0.0579\n",
            "Epoch 11/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 5.5974 - acc: 0.0632\n",
            "Epoch 12/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 5.4973 - acc: 0.0682\n",
            "Epoch 13/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 5.3883 - acc: 0.0767\n",
            "Epoch 14/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 5.2793 - acc: 0.0797\n",
            "Epoch 15/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 5.1713 - acc: 0.0933\n",
            "Epoch 16/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 5.0700 - acc: 0.0994\n",
            "Epoch 17/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.9581 - acc: 0.1099\n",
            "Epoch 18/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.8478 - acc: 0.1185\n",
            "Epoch 19/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.7434 - acc: 0.1272\n",
            "Epoch 20/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.6386 - acc: 0.1387\n",
            "Epoch 21/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.5273 - acc: 0.1498\n",
            "Epoch 22/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.4301 - acc: 0.1574\n",
            "Epoch 23/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.3191 - acc: 0.1700\n",
            "Epoch 24/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.2226 - acc: 0.1819\n",
            "Epoch 25/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.1124 - acc: 0.1933\n",
            "Epoch 26/100\n",
            "15462/15462 [==============================] - 26s 2ms/sample - loss: 4.0072 - acc: 0.2084\n",
            "Epoch 27/100\n",
            "15462/15462 [==============================] - 26s 2ms/sample - loss: 3.9130 - acc: 0.2299\n",
            "Epoch 28/100\n",
            "15462/15462 [==============================] - 26s 2ms/sample - loss: 3.8131 - acc: 0.2474\n",
            "Epoch 29/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.7192 - acc: 0.2646\n",
            "Epoch 30/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.6200 - acc: 0.2798\n",
            "Epoch 31/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.5246 - acc: 0.2959\n",
            "Epoch 32/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.4355 - acc: 0.3194\n",
            "Epoch 33/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.3449 - acc: 0.3384\n",
            "Epoch 34/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.2640 - acc: 0.3550\n",
            "Epoch 35/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.1802 - acc: 0.3780\n",
            "Epoch 36/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.1017 - acc: 0.3947\n",
            "Epoch 37/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.0308 - acc: 0.4083\n",
            "Epoch 38/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 2.9567 - acc: 0.4275\n",
            "Epoch 39/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 2.8920 - acc: 0.4370\n",
            "Epoch 40/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 2.8157 - acc: 0.4576\n",
            "Epoch 41/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 2.7467 - acc: 0.4748\n",
            "Epoch 42/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 2.6853 - acc: 0.4854\n",
            "Epoch 43/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 2.6344 - acc: 0.4975\n",
            "Epoch 44/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 2.5668 - acc: 0.5132\n",
            "Epoch 45/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 2.5150 - acc: 0.5267\n",
            "Epoch 46/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 2.4618 - acc: 0.5349\n",
            "Epoch 47/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 2.4066 - acc: 0.5500\n",
            "Epoch 48/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 2.3595 - acc: 0.5567\n",
            "Epoch 49/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 2.3096 - acc: 0.5735\n",
            "Epoch 50/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 2.2678 - acc: 0.5799\n",
            "Epoch 51/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 2.2058 - acc: 0.5950\n",
            "Epoch 52/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 2.1716 - acc: 0.6013\n",
            "Epoch 53/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 2.1396 - acc: 0.6070\n",
            "Epoch 54/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 2.1059 - acc: 0.6116\n",
            "Epoch 55/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 2.0529 - acc: 0.6230\n",
            "Epoch 56/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 2.0196 - acc: 0.6294\n",
            "Epoch 57/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.9732 - acc: 0.6435\n",
            "Epoch 58/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.9320 - acc: 0.6479\n",
            "Epoch 59/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.9005 - acc: 0.6564\n",
            "Epoch 60/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.8715 - acc: 0.6632\n",
            "Epoch 61/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.8490 - acc: 0.6700\n",
            "Epoch 62/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.8201 - acc: 0.6711\n",
            "Epoch 63/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.7809 - acc: 0.6814\n",
            "Epoch 64/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.7518 - acc: 0.6867\n",
            "Epoch 65/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.7219 - acc: 0.6908\n",
            "Epoch 66/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.6933 - acc: 0.7001\n",
            "Epoch 67/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.6667 - acc: 0.7064\n",
            "Epoch 68/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.6546 - acc: 0.7031\n",
            "Epoch 69/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.6282 - acc: 0.7123\n",
            "Epoch 70/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.6044 - acc: 0.7163\n",
            "Epoch 71/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.5873 - acc: 0.7158\n",
            "Epoch 72/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.5685 - acc: 0.7205\n",
            "Epoch 73/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.5505 - acc: 0.7246\n",
            "Epoch 74/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.5327 - acc: 0.7267\n",
            "Epoch 75/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.4881 - acc: 0.7420\n",
            "Epoch 76/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.4673 - acc: 0.7407\n",
            "Epoch 77/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.4473 - acc: 0.7484\n",
            "Epoch 78/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.4405 - acc: 0.7484\n",
            "Epoch 79/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.4206 - acc: 0.7507\n",
            "Epoch 80/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.4120 - acc: 0.7485\n",
            "Epoch 81/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.3914 - acc: 0.7575\n",
            "Epoch 82/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.3658 - acc: 0.7601\n",
            "Epoch 83/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.3565 - acc: 0.7624\n",
            "Epoch 84/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.3381 - acc: 0.7678\n",
            "Epoch 85/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.3311 - acc: 0.7676\n",
            "Epoch 86/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.3269 - acc: 0.7637\n",
            "Epoch 87/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.2966 - acc: 0.7759\n",
            "Epoch 88/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.2856 - acc: 0.7744\n",
            "Epoch 89/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.2678 - acc: 0.7804\n",
            "Epoch 90/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.2644 - acc: 0.7761\n",
            "Epoch 91/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.2618 - acc: 0.7800\n",
            "Epoch 92/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.2387 - acc: 0.7821\n",
            "Epoch 93/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.2176 - acc: 0.7885\n",
            "Epoch 94/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.2182 - acc: 0.7873\n",
            "Epoch 95/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.2090 - acc: 0.7872\n",
            "Epoch 96/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.1927 - acc: 0.7903\n",
            "Epoch 97/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.1876 - acc: 0.7897\n",
            "Epoch 98/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.1788 - acc: 0.7947\n",
            "Epoch 99/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.1587 - acc: 0.7954\n",
            "Epoch 100/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.1583 - acc: 0.7956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fXTEO3GJ282",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}